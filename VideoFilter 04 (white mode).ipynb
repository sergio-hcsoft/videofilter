{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing packages:\n",
    "  \n",
    "pip install numpy\n",
    "\n",
    "pip install python-opencv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "\n",
    "def relativize(m):\n",
    "    m[m >= 0] = 1+np.log(1+m[m >= 0])\n",
    "    m[m < 0] = np.exp(m[m < 0])\n",
    "    return m\n",
    "\n",
    "\n",
    "class VideoFilter:\n",
    "    def __init__(self, file=0):\n",
    "        self.rate = 0.1       # Update avg with this amount of the new value\n",
    "        self.power = 1        # Strength of the effect, 0 = None, 1 = ok.\n",
    "        self.reduce = 1       # Resolution reduction (1, 2 or 4):\n",
    "        self.max_err = 32     # 10=high sensitivity, 32=noise-free output \n",
    "        self.mode = 0         # different ways of showing the results\n",
    "        self.color_mode = 0   # 0=RGB, 1=grayscxale, 2=HSV \n",
    "        self.save_vid = False # Save the resulting video to file, file name is automatic.\n",
    "        # Open the capture device:\n",
    "        self.open_video(file)\n",
    "        self.time1 = datetime.datetime.now()\n",
    "        self.fps = 0\n",
    "        \n",
    "    def open_video(self, file=0):\n",
    "        # Open webcam device:\n",
    "        self.cap = cv2.VideoCapture(file)\n",
    "        # Redefine size of input images:      \n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH,  self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)  // self.reduce)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT) // self.reduce)\n",
    "        # Read the resulting shape (not always accepted by source)\n",
    "        self.width  = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        # Initialize averages:\n",
    "        self.ini_memory()\n",
    "\n",
    "    def ini_memory(self):\n",
    "        self.get_frame()\n",
    "        self.avg = np.ones(self.frame.shape, dtype=float)*128\n",
    "        self.err = np.ones(self.frame.shape, dtype=float)*128\n",
    "        # Initialize output images:\n",
    "        self.output = cv2.copyMakeBorder(self.frame, 0, 0, 0, 0, cv2.BORDER_REPLICATE)  # BGR\n",
    "        self.triple = cv2.copyMakeBorder(self.frame0, 0, 0, 0, self.width, cv2.BORDER_REPLICATE)\n",
    "        self.last_time = datetime.datetime.now()\n",
    "\n",
    "    def get_frame(self):\n",
    "        ret, self.frame0 = self.cap.read()\n",
    "        if ret:\n",
    "            if (self.color_mode == 0):\n",
    "                self.frame = self.frame0\n",
    "            elif (self.color_mode == 1):\n",
    "                self.frame = cv2.cvtColor(self.frame0, cv2.COLOR_BGR2GRAY)\n",
    "            elif (self.color_mode == 2):\n",
    "                self.frame = cv2.cvtColor(self.frame0, cv2.COLOR_BGR2HSV)\n",
    "        return ret\n",
    "       \n",
    "    def cycle_mode(self):\n",
    "        self.mode = divmod(self.mode + 1, 3)[1]       \n",
    "\n",
    "    def cycle_color_mode(self):\n",
    "        self.color_mode = divmod(self.color_mode + 1, 3)[1]       \n",
    "        self.ini_memory()\n",
    "    \n",
    "    def save_video(self, file_name):\n",
    "        self.save_vid = True\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        self.out = cv2.VideoWriter('output_RT.avi', fourcc, 1.0, (self.triple.shape[0], self.triple.shape[1]), True)\n",
    "        \n",
    "    def end_work(self):\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        if self.save_vid:\n",
    "            self.out.release        \n",
    "        \n",
    "    def process_frame(self):\n",
    "        if (self.mode == 0):\n",
    "            # neutral gray frame gets darker or lighter with movement:\n",
    "            self.coef = relativize((self.frame - self.avg) / self.max_err / 2)\n",
    "            self.coef = np.power(self.coef, self.power)\n",
    "            if (self.color_mode == 2):\n",
    "                self.output[:,:,0] = self.frame[:,:,0]\n",
    "                self.output[:,:,1] = self.frame[:,:,1]\n",
    "                self.output[:,:,2] = np.clip(126 * self.coef[:,:,2], 0, 255)\n",
    "            else:\n",
    "                self.output = np.clip(126 * self.coef, 0, 255)           \n",
    "        if (self.mode == 1):\n",
    "            # black frame gets lighter with movement:\n",
    "            self.coef = relativize(np.abs(self.frame - self.avg) / self.max_err)   \n",
    "            self.coef = np.power(self.coef, self.power) - 1\n",
    "            if (self.color_mode == 2):\n",
    "                self.output[:,:,0] = self.frame[:,:,0]\n",
    "                self.output[:,:,1] = self.frame[:,:,1]\n",
    "                self.output[:,:,2] = np.clip(255 * self.coef[:,:,2], 0, 255)\n",
    "            else:\n",
    "                self.output = np.clip(255 * self.coef, 0, 255)\n",
    "        if (self.mode == 2):\n",
    "            # white frame get darker with movement:\n",
    "            self.coef = relativize(np.abs(self.frame - self.avg) / self.max_err / 2)   \n",
    "            self.coef = np.power(self.coef, self.power) - 1\n",
    "            if (self.color_mode == 2):\n",
    "                self.output[:,:,0] = self.frame[:,:,0]\n",
    "                self.output[:,:,1] = self.frame[:,:,1]\n",
    "                self.output[:,:,2] = np.clip(255 * (1-self.coef[:,:,2]) + self.frame[:,:,2] * self.coef[:,:,2], 0, 255)\n",
    "            else:\n",
    "                self.output = np.clip(255 * (1-self.coef) + self.frame * self.coef, 0, 255)\n",
    "        \n",
    "        # Convert output to BGR mode:       \n",
    "        if (self.color_mode == 1):\n",
    "            self.output = np.uint8(self.output)\n",
    "            self.output = cv2.cvtColor(self.output, cv2.COLOR_GRAY2BGR)\n",
    "        elif (self.color_mode == 2):\n",
    "            self.output = np.uint8(self.output)\n",
    "            self.output = cv2.cvtColor(self.output, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    def update_avg(self):\n",
    "        # Update averaged image:\n",
    "        self.avg = (1-self.rate) * self.avg + self.rate * self.frame        \n",
    "        \n",
    "    def update_output(self):\n",
    "        self.triple[0:self.frame.shape[0], 0:self.frame.shape[1]] = self.frame0\n",
    "        self.triple[0:self.frame.shape[0], self.frame.shape[1]:self.frame.shape[1]*2] = self.output   \n",
    "        # Show final composite image:\n",
    "        cv2.imshow('Relativize video filter', self.triple)    \n",
    "        # write the frame to video:\n",
    "        if self.save_vid:\n",
    "            self.out.write(self.triple)\n",
    "        # update fps:\n",
    "        time2 = datetime.datetime.now()\n",
    "        elapsedTime = time2 - self.time1\n",
    "        self.fps = 1 / elapsedTime.total_seconds()\n",
    "        self.time1 = time2\n",
    "        \n",
    "    def step(self):\n",
    "        if self.get_frame():\n",
    "            self.process_frame()\n",
    "            self.update_avg()\n",
    "            self.update_output()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: 2 fps:  9                  fps:  11                 2 fps:  11                  11                 \r"
     ]
    }
   ],
   "source": [
    "my_filter = VideoFilter() # webcam \n",
    "# my_filter = VideoFilter('Despierta tu diosa.mp4') \n",
    "# my_filter.save_video('output_RT.avi')\n",
    "\n",
    "while(True):  \n",
    "    ret = my_filter.step()   \n",
    "    if ret:\n",
    "        print('mode:', my_filter.mode, 'fps: ', round(my_filter.fps), end='                 \\r')\n",
    "    # Press q, m or c:    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('m'):\n",
    "        my_filter.cycle_mode()\n",
    "    if key == ord('c'):\n",
    "        my_filter.cycle_color_mode()\n",
    "    if (key == ord('q')) or (not ret):\n",
    "        break\n",
    "\n",
    "my_filter.end_work()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
